{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e640032e90a65e5",
   "metadata": {},
   "source": [
    "# Model Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9d24e8b24ea364",
   "metadata": {},
   "source": [
    "## Improvements/Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb02ee3e8f6737",
   "metadata": {},
   "source": [
    "### 1. Time Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754293991db07a79",
   "metadata": {},
   "source": [
    "#### Extreme Time Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2773a7e7f5c7f035",
   "metadata": {},
   "source": [
    "Given the dataset starts in 2012, and we fit until late 2015, it is highly likely that some teams may be completely different (in terms of manager, players, stadium) over the course of such a large time period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fbba6459b339db",
   "metadata": {},
   "source": [
    "It is likely that in late 2015 match results from 2012 are not as informative as match results from 2015.  We can account for this by weighting the match results by time.  We can assume that the weight of a match result is a function of the time difference between the match and the current time.  We can model this as follows:\n",
    "\\begin{equation}\n",
    "    \\text{weight} = \\exp(-\\lambda \\times \\text{time_diff})\n",
    "\\end{equation}\n",
    "Where $\\lambda$ is a hyperparameter that controls the rate at which the weight of a match result decays over time, and $\\text{time_diff}$ is the time difference between the match and the current time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f50808bc6a5eb5a",
   "metadata": {},
   "source": [
    "We can include the above in the model by weighting the likelihood of the observed match results by the time difference between the match and the current time.\n",
    "We may choose a possible small range of values for $\\lambda$ and use cross-validation to determine the best value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1936cdc3551ee",
   "metadata": {},
   "source": [
    "**Can we just pass lambda to scipy.optimize.minimize?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a9e71e4a3e8391",
   "metadata": {},
   "source": [
    "Including lambda as a free parameter in the minimization process may result in failure to converge, or a slow convergence, we can instead use a grid search to find the best value of lambda, across a range of values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4400f94719a0e51f",
   "metadata": {},
   "source": [
    "#### Team Underlying Skill Level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2051fb078dc7351c",
   "metadata": {},
   "source": [
    "On a smaller timescale (i.e within season), the underlying skill of teams is likely to dynamically change over time, there are numerous possible reasons for this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f313b9fca458a1",
   "metadata": {},
   "source": [
    "In this section we will solely consider that the underlying skill level of teams can change over time.  We will not consider the other factors that can cause the skill level of teams to change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad82a0c7a8c2f48",
   "metadata": {},
   "source": [
    "We can assume that at time T the skill level of a team is a function of the skill level of the team at time T-1 and some random noise.  We can model this as follows:\n",
    "\\begin{equation}\n",
    "    \\text{skill}_t = \\text{skill}_{t-1} + \\epsilon\n",
    "\\end{equation}\n",
    "\n",
    "Where $\\epsilon \\sim N(0, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05a64b07715cf82",
   "metadata": {},
   "source": [
    "We may wish to apply above to both the attack and defense ratings of teams. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53743615973bd562",
   "metadata": {},
   "source": [
    "##### Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b9111f1d0aff1",
   "metadata": {},
   "source": [
    "We could extend above by adding a parameter that controls the rate at which the skill level of teams changes over time.  We may allow for more drastic changes in skill level at the start of the season (i.e. due to transfers, new manager etc) and less drastic changes in skill level as the season progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f25cb69ee76945",
   "metadata": {},
   "source": [
    "### 2. Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5dec062f7dcf00",
   "metadata": {},
   "source": [
    "Towards the end of the regular season (especially in the MLS) there are likely to be differing motivations for teams. There is no relegation in the MLS so teams that are unlikely/unable to make the playoffs may not be as motivated to win games. Conversely, teams that are on the cusp of making the playoffs may be more motivated to win games.  It is also possible that teams do not view winning the regular league season as a priority (unlike all other leagues in the world) and may be more focused on the playoffs.<br>\n",
    "In practice this will lead to a team's skill level changing over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6906076470f04",
   "metadata": {},
   "source": [
    "We can use current predictions of the probability of winning regular season league, making playoffs, and include this in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f3582870e95eda",
   "metadata": {},
   "source": [
    "### 3. Home Advantage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf305081ad48f54",
   "metadata": {},
   "source": [
    "We can improve the modelling of home advantage.  We may want to have separate home advantage parameters for each conference, i.e. when the same conference is playing each other, and a value for when teams from different conferences are playing each other.\n",
    "\n",
    "i.e.\n",
    "\\begin{equation}\n",
    "    \\text{home_advantage} = \\begin{cases} \n",
    "        \\text{home_advantage_same_conference} & \\text{if teams in same conference} \\\\\n",
    "        \\text{home_advantage_diff_conference} & \\text{if teams in different conferences}\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "where \n",
    "\\begin{equation}\n",
    "    \\text{home_advantage_same_conference} = \\begin{cases} \n",
    "        \\text{east_home_advantage} & \\text{if both in eastern conference} \\\\\n",
    "        \\text{west_home_advantage} & \\text{if both in western conference}\n",
    "    \\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d1e196ffde009",
   "metadata": {},
   "source": [
    "We may wish to further expand upon above, there may be differing home advantages observed due to:\n",
    "- Altitude of stadium (Colorado Rapids play at 5000 + feet)\n",
    "- Weather conditions players are used to playing in\n",
    "- Distance of travel (**It is likely that the analysis from question 2 is a proxy for differences in travel distance**)\n",
    "- Time spent in stadium (i.e. familiarity with stadium and pitch dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cbfcd824bbf0b6",
   "metadata": {},
   "source": [
    "#### Hierarchical Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b1c6999f89c0bf",
   "metadata": {},
   "source": [
    "We could use a simple Hierarchical Model as a starting point for the home advantage model.  We could assume that the home advantage for each team is drawn from a normal distribution with mean $\\mu$ and standard deviation $\\sigma$.\n",
    "\\begin{equation}\n",
    "    \\text{home_advantage}_i \\sim N(\\mu, \\sigma)\n",
    "\\end{equation}\n",
    "Where $\\mu$ and $\\sigma$ are hyperparameters.  We could then model $\\mu$ and $\\sigma$ as follows:\n",
    "\\begin{equation}\n",
    "    \\mu \\sim N(\\mu_0, \\sigma_0)\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    \\sigma \\sim \\text{HalfCauchy}(\\beta)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a1a2bb66fb903",
   "metadata": {},
   "source": [
    "We could expand upon above by adding levels to the hierarchical model, i.e. we could have a separate $\\mu$ for each conference, and a separate $\\mu$ for each team in the conference.  We could also add additional levels to the model to account for the other factors that may impact home advantage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da88cca65b45e253",
   "metadata": {},
   "source": [
    "### 4. Underlying Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364c7cea00b9a85a",
   "metadata": {},
   "source": [
    "In the basic model we assumed that home and away goals were independent, in practice the two teams goals are inherently correlated and psychological factors can play a role in the outcome of games. <br>\n",
    "Most teams will be employing the \"strategy\" of winning games, however sometimes teams may be more focused on not losing games (due to significant differences in skill, conventional wisdom on the best result for a game etc), this can lead to different correlations between home and away goals depending on the fixture, and also the current score (game-state) of the game. <br>\n",
    "Expanding upon above, once a team goes ahead/behind in a game there will likely be changes (both conscious and subconscious) in the way the team plays.  This can lead to differing correlations between home and away goals depending on the current score of the game. <br>\n",
    "Conscious changes might include:\n",
    "- Substitutions\n",
    "- Formation changes\n",
    "- Tactical changes\n",
    "- Time wasting\n",
    "- Pressing\n",
    "- etc.\n",
    "Subconscious changes might include:\n",
    "- Players taking less risks\n",
    "- Players being more cautious\n",
    "- Players being more aggressive\n",
    "- Players feeling more or less pressure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb6ee520945df80",
   "metadata": {},
   "source": [
    "#### Possible Model Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02d6882f1d4606d",
   "metadata": {},
   "source": [
    "##### Remove Constant Baseline Goal Expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dce92ebe2554378",
   "metadata": {},
   "source": [
    "In the previous model we used the $\\gamma$ parameter to model the baseline goal expectation.  In practice, we would not expect the baseline goal expectation to be constant, since different skill levels and tactical approaches will lead to different baseline goal expectations. The model is simplified below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d1bff1756c83",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    \\lambda_{i, j} = \\exp(\\text{attack}_i + \\text{defense}_j + \\text{home_advantage})\n",
    "\\end{equation}\n",
    "\n",
    "Where $\\text{attack}_i$ is the attack rating of team i, $\\text{defense}_j$ is the defense rating of team j, and $\\text{home_advantage}$ is the home advantage.\n",
    "\n",
    "We still include sum to zero constraints on the attack and defense ratings.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\sum_{i=1}^{n} \\text{attack}_i = 0\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    \\sum_{j=1}^{n} \\text{defense}_j = 0\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f8356f544a268",
   "metadata": {},
   "source": [
    "We can introduce models that allow for correlation between home and away goals, some possible options here are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f433458490592e",
   "metadata": {},
   "source": [
    "##### Dixon Coles Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d1ebf88628241",
   "metadata": {},
   "source": [
    "It is likely the previous model will underestimate low score lines and overestimate high score lines.  This is likely due to some of the previously listed reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521d72d89bd706",
   "metadata": {},
   "source": [
    "The Dixon Coles model introduces a parameter $\\rho$ that \"corrects\" the model for this, acting as a correlation/dependence parameter between home and away goals. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23820b50b0e5805a",
   "metadata": {},
   "source": [
    "##### Bivariate Poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3bc15a2c6aa728",
   "metadata": {},
   "source": [
    "We can use a Bivariate Poisson distribution to model the number of goals scored by each team.  The Bivariate Poisson distribution is a generalization of the Poisson distribution to two dimensions.  The Bivariate Poisson distribution is parameterized by three parameters $\\lambda_1$ $\\lambda_2$ and $\\rho$ where $\\lambda_1$ and $\\lambda_2$ are the means of the two Poisson distributions and $\\rho$ is the correlation between the two Poisson distributions.  The probability mass function of the Bivariate Poisson distribution is given by:\n",
    "\\begin{equation}\n",
    "    P(X = x, Y = y) = \\frac{e^{-(\\lambda_1 + \\lambda_2)}(\\lambda_1^{x} \\lambda_2^{y})}{x!y!} \\sum_{k=0}^{\\min(x, y)} \\frac{x!y!\\rho^k}{k!(x-k)!(y-k)!}\n",
    "\\end{equation}\n",
    "\n",
    "Where $X$ and $Y$ are the number of goals scored by each team, and $x$ and $y$ are the number of goals scored by each team.  The correlation between the two Poisson distributions is given by $\\rho$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df8602c02faf8a",
   "metadata": {},
   "source": [
    "Advantages:\n",
    "- Captures dependency between home and away goals\n",
    "- Can easily be implemented\n",
    "\n",
    "Disadvantages:\n",
    "- Assumes that the number of goals scored by each team is Poisson distributed\n",
    "- Only allows for positive dependency between home and away goals. (CHECK THIS?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b369ee618b27d",
   "metadata": {},
   "source": [
    "## Additional Data\n",
    "- Manager information\n",
    "- Lineup information for each game\n",
    "- Stadium location and altitude\n",
    "- Weather conditions for each game\n",
    "- Travel information for each game (i.e. distance travelled, time spent travelling)\n",
    "- Cup/internation fixtures (for fatigue, travelling, rotation etc)\n",
    "- Event Data/Tracking Data (We can improve upon using observed goals to fit ratings models, i.e XG model)\n",
    "    - Even goal information (i.e. penalty/non penalty) could improve the model\n",
    "- Referee information (Penalty tendencies, card tendencies etc)\n",
    "- League rules or rules changes\n",
    "    - (i.e. introduction of VAR for red card, penalty decisions etc)\n",
    "    - (i.e. change in number of substitutes allowed)\n",
    "    - (i.e. drastic changes in stoppage time played)\n",
    "- Market information (betting market information)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf23bfa60e2f408",
   "metadata": {},
   "source": [
    "## Given Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8824c16f78a1ab",
   "metadata": {},
   "source": [
    "We now use the seasonal pattern detected in the total goal scores.  We modify the model to allow for this by extending from one gamma parameter to 12 gamma parameters, one for each month of the year, i.e.,\n",
    "$$ X_k \\sim \\text{Poisson}(\\lambda_k) $$\n",
    "$$ Y_k \\sim \\text{Poisson}(\\mu_k) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\ln \\lambda_k = \\alpha_{i(k)} + \\beta_{j(k)} + \\gamma_m + \\frac{\\eta}{2} $$\n",
    "$$ \\ln \\mu_k = \\alpha_{j(k)} + \\beta_{i(k)} + \\gamma_m +  \\frac{\\eta}{2} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd220b14c4125b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 matches from the test set.\n"
     ]
    }
   ],
   "source": [
    "from smartodds.data_fetching.prepare_data import ExtendedModel, SimpleModel\n",
    "from tabulate import tabulate\n",
    "\n",
    "extended_model = ExtendedModel('merged_data.csv','data_mls_simset_predictions.csv')\n",
    "extended_model.fit()\n",
    "extended_model.add_predictions()\n",
    "extended_eval=extended_model.evaluate()\n",
    "comparison_eval=extended_model.evaluate_comparison_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83f784f77aa4f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimisation outcome: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH, is successful: True, log likelihood: -3923.0644668025875, number of iterations: 26\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Minimisation outcome: {extended_model.result.message}, is successful: {extended_model.result.success}, log likelihood: {-extended_model.result.fun}, number of iterations: {extended_model.result.nit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affc16acb8a2bec6",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d024b54eeca241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 matches from the test set.\n"
     ]
    }
   ],
   "source": [
    "simple_model = SimpleModel('merged_data.csv','data_mls_simset_predictions.csv')\n",
    "simple_model.fit()\n",
    "simple_model.add_predictions()\n",
    "simple_eval=simple_model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95aaaae208256e9",
   "metadata": {},
   "source": [
    "### Fit Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a1884af18de9a5",
   "metadata": {},
   "source": [
    "We cannot just compare the 2 likelihood values of the models since the models have different numbers of parameters.  We can start with a few approaches below, to assess fit, **BUT** we will prioritize evaluation of the models vs unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce093e03bb448e82",
   "metadata": {},
   "source": [
    "### Evaluation vs Unseen Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e553e28ffd76898d",
   "metadata": {},
   "source": [
    "The approach used below is unlikely to mirror a production model, where the model will constantly be fit when new data is received.  We will compare the 2 models by taking the fitted model and using it to predict the outcomes of the test set.  We will then compare the predicted outcomes to the actual outcomes, using a set of evaluation metrics.  We will use the following metrics:\n",
    "- Log Loss: This is a common metric used in classification problems, it is the negative log likelihood of the model.  It is a measure of how well the model predicts the actual outcomes.  The lower the log loss the better the model.\n",
    "- Brier Score: This is a common metric used in classification problems, it is the mean squared difference between the predicted probabilities and the actual outcomes.  The lower the Brier Score the better the model.\n",
    "- Bias: This is the mean difference between the predicted probabilities and the actual outcomes.  The lower the bias the better the model.\n",
    "- RMSE: We use the RMSE to compare to observed event counts.  The lower the RMSE the better the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd97ea8",
   "metadata": {},
   "source": [
    "We use probabilistic scores for evaluating the predicted outcomes, and we will use RMSE to evaluate the models against 'expected goals'. If we had probabilistic predictions for goals markets we could use the same metrics as above to evaluate the models against the goals markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef81bd4949df05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'home_log_loss': np.float64(0.6979880473806059),\n",
       " 'away_log_loss': np.float64(0.5083130615917607),\n",
       " 'draw_log_loss': np.float64(0.6357780326785211),\n",
       " 'mean_log_loss': np.float64(0.6140263805502958),\n",
       " 'home_brier_score': np.float64(0.2523681504106389),\n",
       " 'away_brier_score': np.float64(0.16299369352002988),\n",
       " 'draw_brier_score': np.float64(0.22062311998451123),\n",
       " 'mean_brier_score': np.float64(0.21199498797172667),\n",
       " 'home_bias': np.float64(-0.0008390367891279646),\n",
       " 'away_bias': np.float64(0.07170518515265985),\n",
       " 'draw_bias': np.float64(-0.07086614836353189),\n",
       " 'mean_bias': np.float64(0.0),\n",
       " 'home_rmse': np.float64(0.5023625686798718),\n",
       " 'away_rmse': np.float64(0.40372477446898136),\n",
       " 'draw_rmse': np.float64(0.4697053544345766),\n",
       " 'mean_rmse': np.float64(0.45859756586114325),\n",
       " 'total_goals_rmse': np.float64(1.702947437469505)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Simple Model:\")\n",
    "simple_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f83007a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended Model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'home_log_loss': np.float64(0.6992760108210303),\n",
       " 'away_log_loss': np.float64(0.5079846666185494),\n",
       " 'draw_log_loss': np.float64(0.6382042229896407),\n",
       " 'mean_log_loss': np.float64(0.6151549668097401),\n",
       " 'home_brier_score': np.float64(0.2529960835743615),\n",
       " 'away_brier_score': np.float64(0.16289828994945452),\n",
       " 'draw_brier_score': np.float64(0.2214445959223487),\n",
       " 'mean_brier_score': np.float64(0.21244632314872156),\n",
       " 'home_bias': np.float64(-0.0007311687939184144),\n",
       " 'away_bias': np.float64(0.07151714506620224),\n",
       " 'draw_bias': np.float64(-0.07078597627228382),\n",
       " 'mean_bias': np.float64(4.625929269271485e-18),\n",
       " 'home_rmse': np.float64(0.5029871604468265),\n",
       " 'away_rmse': np.float64(0.40360660295571793),\n",
       " 'draw_rmse': np.float64(0.4705790007239472),\n",
       " 'mean_rmse': np.float64(0.4590575880421639),\n",
       " 'total_goals_rmse': np.float64(1.7112895588062458)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Extended Model:\")\n",
    "extended_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36802a45fc3b93f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'home_log_loss': np.float64(0.6810377829938471),\n",
       " 'away_log_loss': np.float64(0.479863620387127),\n",
       " 'draw_log_loss': np.float64(0.6257773180681283),\n",
       " 'mean_log_loss': np.float64(0.5955595738163675),\n",
       " 'home_brier_score': np.float64(0.24401575054001173),\n",
       " 'away_brier_score': np.float64(0.15115041887392827),\n",
       " 'draw_brier_score': np.float64(0.2165265939016754),\n",
       " 'mean_brier_score': np.float64(0.2038975877718718),\n",
       " 'home_bias': np.float64(-0.001179942851744113),\n",
       " 'away_bias': np.float64(0.06428779474892794),\n",
       " 'draw_bias': np.float64(-0.06310785189718383),\n",
       " 'mean_bias': np.float64(0.0),\n",
       " 'home_rmse': np.float64(0.4939795041699723),\n",
       " 'away_rmse': np.float64(0.3887806822283333),\n",
       " 'draw_rmse': np.float64(0.46532418151400146),\n",
       " 'mean_rmse': np.float64(0.44936145597076904),\n",
       " 'total_goals_rmse': np.float64(1.699939464112186)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Comparison Model:\")\n",
    "comparison_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d1b8d5",
   "metadata": {},
   "source": [
    "#### Caveats\n",
    "We cannot just compare the models values for say mean log loss and say for certain that one model is better than the other. We may choose to use a bootstrap approach to determine if the difference in the evaluation metrics is statistically significant.\n",
    "We may encounter issues where one model performs better for one purpose (i.e. predict match result) and the other model performs better for another purpose (i.e. predict total goals).  We may need to make a decision on which model to use based on the purpose of the model.\n",
    "If the end use of the model is to bet on the outcomes of games, we may wish to evaluate against available implied probabilities, however care needs to be taken since markets are always evolving and market accuracy may be improving over time.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
